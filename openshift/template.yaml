apiVersion: template.openshift.io/v1
kind: Template
metadata:
  name: assisted-events-scrape
objects:
# Assisted events scrape k8s manifests
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: assisted-events-scrape
  spec:
    selector:
      matchLabels:
        app: assisted-events-scrape
    replicas: ${{REPLICAS_COUNT}}
    template:
      metadata:
        labels:
          app: assisted-events-scrape
      spec:
        serviceAccountName: assisted-service
        containers:
        - name: assisted-events-scrape
          image: ${IMAGE_NAME}:${IMAGE_TAG}
          imagePullPolicy: ${IMAGE_PULL_POLICY}
          resources:
            limits:
              cpu: 500m
              memory: 2000Mi
            requests:
              cpu: 300m
              memory: 400Mi
          envFrom:
            - secretRef:
                name: events-scrape
          env:
          - name: SENTRY_DSN
            value: "${SENTRY_DSN}"
          - name: SENTRY_RELEASE
            value: "${IMAGE_TAG}"
          - name: MAX_IDLE_MINUTES
            value: "${MAX_IDLE_MINUTES}"
          - name: ERRORS_BEFORE_RESTART
            value: "${ERRORS_BEFORE_RESTART}"
          - name: N_WORKERS
            value: "${N_WORKERS}"
          - name: LOGLEVEL
            value: "${LOGLEVEL}"
          - name: ES_SERVER
            valueFrom:
              secretKeyRef:
                key: endpoint
                name: assisted-installer-elasticsearch
          - name: ES_INDEX
            value: "${ES_INDEX}"
          - name: ES_USER
            valueFrom:
              secretKeyRef:
                key: master_user_name
                name: elastic-master-credentials
          - name: ES_PASS
            valueFrom:
              secretKeyRef:
                key: master_user_password
                name: elastic-master-credentials
# Kibana manifests
# Using service account as an Oauth client. read https://access.redhat.com/documentation/en-us/openshift_container_platform/4.2/html/authentication/using-service-accounts-as-oauth-client
- apiVersion: v1
  kind: ServiceAccount
  metadata:
    annotations:
      # Ensuring the redirect url will be the kibana route
      serviceaccounts.openshift.io/oauth-redirectreference.primary: '{"kind":"OAuthRedirectReference","apiVersion":"v1","reference":{"kind":"Route","name":"kibana-proxy"}}'
    name: kibana-proxy
- apiVersion: v1
  kind: Service
  metadata:
    labels:
      app: kibana-proxy
    name: kibana-proxy
  spec:
    ports:
    - port: 3000
      protocol: TCP
      targetPort: 3000
    selector:
      app: kibana
    sessionAffinity: None
    type: ClusterIP
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: kibana
    labels:
      app: kibana
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: kibana
    template:
      metadata:
        labels:
          app: kibana
      spec:
        serviceAccountName: kibana-proxy
        containers:
        - name: kibana-proxy
          image: ${OAUTH_IMAGE}:${OAUTH_IMAGE_TAG}
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 3000
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /oauth/healthz
              port: http
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              cpu: 50m
              memory: 100Mi
            requests:
              cpu: 50m
              memory: 100Mi
          args:
          - --http-address=0.0.0.0:3000
          - --provider=openshift
          - --openshift-service-account=kibana-proxy
          - --upstream=$(ENDPOINT)
          - --https-address=
          - --pass-basic-auth=false
          - --openshift-sar={"namespace":"$(NAMESPACE)","resource":"services","name":"kibana-proxy","verb":"get"}
          - --htpasswd-file=/etc/oauth-proxy/htpasswd
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: ENDPOINT
            valueFrom:
              secretKeyRef:
                key: endpoint
                name: assisted-installer-elasticsearch
          - name: OAUTH2_PROXY_COOKIE_SECRET
            valueFrom:
              secretKeyRef:
                key: session_secret
                name: kibana-oauth-application
          volumeMounts:
          - mountPath: /etc/oauth-proxy/
            name: oauth-proxy-htpasswd
            readOnly: true
        volumes:
        - name: oauth-proxy-htpasswd
          secret:
            defaultMode: 420
            optional: false
            secretName: kibana-oauth-application
            items:
            - key: htpasswd
              path: htpasswd
# Elasticsearch data migration job. To be deleted once completed
- apiVersion: batch/v1
  kind: Job
  metadata:
    name: load-historical-data-${JOB_NAME}
  spec:
    backoffLimit: 0
    completions: 1
    parallelism: 1
    suspend: ${{SUSPEND_JOBS}}
    template:
      spec:
        containers:
        - command:
          - bash
          args:
          - "-c"
          - "ELASTIC_AUTH_HOST=https://${ELASTIC_USER}:${ELASTIC_PASSWORD}@${ELASTIC_HOST:8};\
   for index in ${MIGRATION_INDICES//,/ }; do \
     aws s3 cp s3://${AWS_S3_BUCKET}/migration-v2_${index}.json .
     migration_index=restored_${index}; \
     echo 'Migrating '${migration_index}'...'; \
     elasticdump --input=./migration-v2_${index}.json --output=${ELASTIC_AUTH_HOST}/${migration_index} --limit=${ELASTICDUMP_LIMIT} --offset=${ELASTICDUMP_OFFSET} --concurrency=${ELASTICDUMP_CONCURRENCY} --concurrencyInterval=${ELASTICDUMP_CONCURRENCY_INTERVAL} --intervalCap=${ELASTICDUMP_INTERVAL_CAP} ; \
     rm -f migration-v2_${index}.json ; \
   done"
          env:
          - name: ELASTIC_HOST
            valueFrom:
              secretKeyRef:
                key: endpoint
                name: assisted-installer-elasticsearch
          - name: MIGRATION_INDICES
            value: "${MIGRATION_INDICES}"
          - name: ELASTICDUMP_LIMIT
            value: "${ELASTICDUMP_LIMIT}"
          - name: ELASTICDUMP_OFFSET
            value: "${ELASTICDUMP_OFFSET}"
          - name: ELASTICDUMP_CONCURRENCY
            value: "${ELASTICDUMP_CONCURRENCY}"
          - name: ELASTICDUMP_CONCURRENCY_INTERVAL
            value: "${ELASTICDUMP_CONCURRENCY_INTERVAL}"
          - name: ELASTICDUMP_INTERVAL_CAP
            value: "${ELASTICDUMP_INTERVAL_CAP}"
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                key: aws_access_key_id
                name: assisted-installer-s3-migration
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                key: aws_secret_access_key
                name: assisted-installer-s3-migration
          - name: AWS_S3_BUCKET
            valueFrom:
              secretKeyRef:
                key: bucket
                name: assisted-installer-s3-migration
          - name: ELASTIC_USER
            valueFrom:
              secretKeyRef:
                key: master_user_name
                name: elastic-master-credentials
          - name: ELASTIC_PASSWORD
            valueFrom:
              secretKeyRef:
                key: master_user_password
                name: elastic-master-credentials
          image: ${ELASTICDUMP_IMAGE}
          imagePullPolicy: ${ELASTICDUMP_IMAGE_PULL_POLICY}
          name: elastic-dump
        restartPolicy: Never
parameters:
- name: IMAGE_NAME
  value: quay.io/app-sre/assisted-events-scrape
- name: IMAGE_TAG
  value: ''
  required: true
- name: REPLICAS_COUNT
  value: "1"
- name: ES_INDEX
  value: 'assisted-service-events'
- name: OAUTH_IMAGE
  value: quay.io/openshift/origin-oauth-proxy
- name: OAUTH_IMAGE_TAG
  value: 4.4.0
- name: SENTRY_DSN
  value: ''
- name: MAX_IDLE_MINUTES
  value: '120'
- name: ERRORS_BEFORE_RESTART
  value: '10000'
- name: N_WORKERS
  value: '5'
- name: LOGLEVEL
  value: 'INFO'
- name: IMAGE_PULL_POLICY
  value: 'Always'
- name: SUSPEND_JOBS
  value: "false"
# Below parameters for migration job, to be deleted
- name: JOB_NAME
  value: "march-2021"
- name: ELASTICDUMP_IMAGE
  value: "quay.io/app-sre/elasticdump:v6.82.3"
- name: ELASTICDUMP_IMAGE_PULL_POLICY
  value: 'Always'
- name: ELASTICDUMP_LIMIT
  value: "100"
- name: ELASTICDUMP_OFFSET
  value: "0"
- name: MIGRATION_INDICES
  value: "assisted-service-events_2021-03"
- name: ELASTICDUMP_CONCURRENCY
  value: "100"
- name: ELASTICDUMP_CONCURRENCY_INTERVAL
  value: "1000"
- name: ELASTICDUMP_INTERVAL_CAP
  value: "100"
